{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic modelling\n",
    "This notebook explores the science of topic modelling, where from a text dataset we want to obtain similar topics. [There are many authors that explored this](http://delivery.acm.org/10.1145/2140000/2133826/p77-blei.pdf?ip=77.227.30.78&id=2133826&acc=OPEN&key=4D4702B0C3E38B35%2E4D4702B0C3E38B35%2E4D4702B0C3E38B35%2E6D218144511F3437&__acm__=1568126591_4585170a693dc7e37a93b845996026ca).\n",
    "\n",
    "This is going to be a practical hands-on experience notebook where we will cover the following:\n",
    "\n",
    " - Text preprocessing.\n",
    " - Text transformation (TF-IDF, Word2vec)\n",
    " - Algorithms based on signal decomposition:\n",
    "     - Latent Dirichlet Allocation. (Using TF-IDF).\n",
    "     - Non-negative Matrix Factorization (using TF-IDF).\n",
    " - Clustering algorithms:\n",
    "     - K-means + TF-IDF.\n",
    " - Algorithms based on similarity:\n",
    "     - WordVectors + Cosine similarity + np masked array.\n",
    "\n",
    "Please note that **all the models require a text transformation**. That's it, either using TD-IDF or Word2Vec."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>\n",
       "    code_show=true; \n",
       "    function code_toggle() {\n",
       "     if (code_show){\n",
       "     $('div.input').hide();\n",
       "     } else {\n",
       "     $('div.input').show();\n",
       "     }\n",
       "     code_show = !code_show\n",
       "    } \n",
       "    $( document ).ready(code_toggle);\n",
       "    </script>\n",
       "    To toggle <a href=\"javascript:code_toggle()\">on/off</a> the raw code."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.core.display import Image, display\n",
    "\n",
    "from IPython.display import HTML\n",
    "HTML('''<script>\n",
    "    code_show=true; \n",
    "    function code_toggle() {\n",
    "     if (code_show){\n",
    "     $('div.input').hide();\n",
    "     } else {\n",
    "     $('div.input').show();\n",
    "     }\n",
    "     code_show = !code_show\n",
    "    } \n",
    "    $( document ).ready(code_toggle);\n",
    "    </script>\n",
    "    To toggle <a href=\"javascript:code_toggle()\">on/off</a> the raw code.''')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from time import time\n",
    "import string\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set model parameters:\n",
    "n_samples = 2000\n",
    "n_features = 1000\n",
    "n_components = 10\n",
    "n_top_words = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample data downloading\n",
    "In this notebook we will be using the 20 newsgroup dataset. \n",
    "Scikit has an utility that can download datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading 20news dataset. This may take a few minutes.\n",
      "Downloading dataset from https://ndownloader.figshare.com/files/5975967 (14 MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n",
      "done in 180.182s.\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading dataset...\")\n",
    "t0 = time()\n",
    "dataset = fetch_20newsgroups(shuffle=True, random_state=1,\n",
    "                             remove=('headers', 'footers', 'quotes'))\n",
    "data_samples = dataset.data[:n_samples]\n",
    "print(\"done in %0.3fs.\" % (time() - t0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the sake of simplicity we will create a Pandas Series, so all functions here ara compatible with a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = pd.Series(data_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Well i'm not sure about the story nad it did s...\n",
       "1    \\n\\n\\n\\n\\n\\n\\nYeah, do you expect people to re...\n",
       "2    Although I realize that principle is not one o...\n",
       "3    Notwithstanding all the legitimate fuss about ...\n",
       "4    Well, I will have to change the scoring on my ...\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(texts.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use some utility functions that print the top words per topic and to produce a dataframe where we will compare the assigned topic for each different technique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#utils function\n",
    "def print_top_words(model, feature_names, n_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        message = \"Topic #%d: \" % topic_idx\n",
    "        message += \" \".join([feature_names[i]\n",
    "                             for i in topic.argsort()[:-n_top_words - 1:-1]])\n",
    "        print(message)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_topics(model,tf):\n",
    "    topic_matrix = lda.transform(tf)\n",
    "    topics = []\n",
    "    for ele in topic_matrix:\n",
    "        topics.append(np.argmax(ele))\n",
    "    return topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text cleaning\n",
    "We are going to remove:\n",
    "- non-printable characters.\n",
    "- punctuations: please note that this would remove some meaning and it won't be successful with word vectors.\n",
    "- standalone numbers and standalone characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr = str.maketrans(string.punctuation,' '*len(string.punctuation))\n",
    "single_char = r\"\\b[a-zA-Z]\\b\"\n",
    "number_regex = r\"\\b\\d+\\b\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove punctuation\n",
    "texts = texts.str.translate(tr)\n",
    "#remove single chars\n",
    "texts = texts.str.replace(single_char,'')\n",
    "#remove all numbers\n",
    "texts = texts.str.replace(number_regex,'')\n",
    "#remove line breaks win,linux, macOS\n",
    "texts = texts.str.replace('\\n','')\n",
    "texts = texts.str.replace('\\r','')\n",
    "#remove tabs:\n",
    "texts = texts.str.replace('\\t','')\n",
    "# remove trailing whitespaces\n",
    "texts = texts.str.strip()\n",
    "# remove whitespaces in string\n",
    "texts = texts.str.replace(' +', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Well not sure about the story nad it did seem ...\n",
       "1    Yeah do you expect people to read the FAQ etc ...\n",
       "2    Although realize that principle is not one of ...\n",
       "3    Notwithstanding all the legitimate fuss about ...\n",
       "4    Well will have to change the scoring on my pla...\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(texts.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text preprocessing\n",
    "We are going to:\n",
    " - lowercase the text.\n",
    " - tokenize.\n",
    " - vectorize and calculate the TF-IDF.\n",
    "Some other preprocessing not done here [check this link from Stanford NLP group](https://nlp.stanford.edu/IR-book/html/htmledition/stemming-and-lemmatization-1.html). These techniques are useful when using Bag of Words approaches.:\n",
    " - Stemming: getting the root of the word by applying heuristics (see Porter's Stemmer).\n",
    " ![Sample of Stemm](img/img100.png)\n",
    " - Lemmatization: getting the root of the words by using morphological analysis.\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = texts.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    well not sure about the story nad it did seem ...\n",
       "1    yeah do you expect people to read the faq etc ...\n",
       "2    although realize that principle is not one of ...\n",
       "3    notwithstanding all the legitimate fuss about ...\n",
       "4    well will have to change the scoring on my pla...\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(texts.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text transformation\n",
    "Remember the algorithms only understand a numerical representation, so we have to choose:\n",
    " - Term frecuency. (TF)\n",
    " - Term frecuency, inverse document frecuency. (TF-IDF).\n",
    " - Word Vectors.\n",
    " \n",
    "Please note that there are other approaches like bags of words. See the tutorial [working with text data](https://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html) from Scikit-learn.\n",
    "\n",
    "### Create a full tf-idf vectorizer for our text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(max_df=0.95, min_df=2,\n",
    "                                   max_features=n_components,\n",
    "                                   stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = tfidf_vectorizer.fit_transform(texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a term frecuency vectorizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_vectorizer = CountVectorizer(max_df=0.95, min_df=2,\n",
    "                                max_features=n_components,\n",
    "                                stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = tf_vectorizer.fit_transform(texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Latent Dirichlet Allocation:\n",
    "The graphical model of LDA is a three-level generative model:\n",
    "See the [scikit link.](https://scikit-learn.org/stable/modules/decomposition.html#latentdirichletallocation)\n",
    "\n",
    "![Latent Diriletch Allocation](img/lda_model_graph.png)\n",
    "\n",
    "\n",
    "Note on notations presented in the graphical model above, which can be found in Hoffman et al. (2013):\n",
    "\n",
    " - The corpus is a collection of *D* documents.\n",
    " - A document is a sequence of *W* words.\n",
    " - There are *K* topics in the corpus.\n",
    " \n",
    "The boxes represent repeated sampling.\n",
    "\n",
    " - Method explained here: http://jmlr.csail.mit.edu/papers/v3/blei03a.html\n",
    " - Classification example: https://scikit-learn.org/stable/auto_examples/applications/plot_topics_extraction_with_nmf_lda.html#sphx-glr-auto-examples-applications-plot-topics-extraction-with-nmf-lda-py\n",
    "\n",
    "We are going to:\n",
    " - Select the language (in this case english).\n",
    " - Preprocess the text (**In this example we will consider the text is already preprocessed**)\n",
    " - Compute the tf-idf for the text.\n",
    " - Compute the LDA\n",
    " - Use the Non-negative factor matrix decomposition to get the topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = LatentDirichletAllocation(n_components=n_components, max_iter=5,\n",
    "                                learning_method='online',\n",
    "                                learning_offset=50.,\n",
    "                                random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 1.721s.\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "lda.fit(tf)\n",
    "print(\"done in %0.3fs.\" % (time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "#topics(lda,texts)\n",
    "cluster_lda = pd.Series(cluster_topics(lda,tf),index=texts.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topics in LDA model:\n",
      "Topic #0: just like know don people time new think use edu\n",
      "Topic #1: know don like people think just time use new edu\n",
      "Topic #2: don think use like just people new know time edu\n",
      "Topic #3: think time just don like people know use new edu\n",
      "Topic #4: people time know new like don just use think edu\n",
      "Topic #5: just think like edu know use new don time people\n",
      "Topic #6: new time just know use don like think edu people\n",
      "Topic #7: edu like use time new know don just people think\n",
      "Topic #8: use know don just people like time think edu new\n",
      "Topic #9: like time use new just think don know people edu\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nTopics in LDA model:\")\n",
    "tf_feature_names = tf_vectorizer.get_feature_names()\n",
    "print_top_words(lda, tf_feature_names, n_top_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Non-negative matrix factorization\n",
    "Two methods:\n",
    " - Frobenius norm\n",
    " - Generalized Kullback-Leibler divergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.346s.\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "nmf = NMF(n_components=n_components, random_state=1,\n",
    "          alpha=.1, l1_ratio=.5).fit(tfidf)\n",
    "print(\"done in %0.3fs.\" % (time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_nmf = pd.Series(cluster_topics(nmf,tfidf),index=texts.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #0: people just think know time don like use new edu\n",
      "Topic #1: edu use time think people new like know just don\n",
      "Topic #2: like just don know use time think people new edu\n",
      "Topic #3: time like new just people know think don use edu\n",
      "Topic #4: know don people like just time use think new edu\n",
      "Topic #5: just like don think people time know new use edu\n",
      "Topic #6: think don just people like time use new know edu\n",
      "Topic #7: new time just like use think people know edu don\n",
      "Topic #8: use like just don time think people new know edu\n",
      "Topic #9: don know just like think people use time new edu\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tfidf_feature_names = tfidf_vectorizer.get_feature_names()\n",
    "print_top_words(nmf, tfidf_feature_names, n_top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.158s.\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "nmf2 = NMF(n_components=n_components, random_state=1,\n",
    "          beta_loss='kullback-leibler', solver='mu', max_iter=1000, alpha=.1,\n",
    "          l1_ratio=.5).fit(tfidf)\n",
    "print(\"done in %0.3fs.\" % (time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_nmf2 = pd.Series(cluster_topics(nmf2,tfidf),index=texts.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #0: people think know don like just use time new edu\n",
      "Topic #1: edu use time think people new like know just don\n",
      "Topic #2: like think just know don use time people new edu\n",
      "Topic #3: time know like people just use think new edu don\n",
      "Topic #4: know think don just use time people new like edu\n",
      "Topic #5: just think know like don use time people new edu\n",
      "Topic #6: time think use people new like know just edu don\n",
      "Topic #7: new think use time people like know just edu don\n",
      "Topic #8: use know like time think people new just edu don\n",
      "Topic #9: don know think like just use time people new edu\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# tfidf_feature_names = tfidf_vectorizer.get_feature_names()\n",
    "print_top_words(nmf2, tfidf_feature_names, n_top_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering with K-means\n",
    "You can check the full example [here](https://scikit-learn.org/stable/auto_examples/text/plot_document_clustering.html#sphx-glr-auto-examples-text-plot-document-clustering-py).\n",
    "\n",
    "In this case we will not reduce the dimensionality (using LSA), neither normalizing the input (using a truncated SVD + Normalized).\n",
    "\n",
    "**The number of clusters is not known beforehand**. The algorithm needs as input the number of cluster. A **good** estimation is to use the Silhouette coefficient (a value in teh range [0,1]). The main drawback is that in order to do the estimation, we have to compute the k-means and then the silhouette coefficient.\n",
    "\n",
    "In this example we will compute manually for 2 and 10 clusters, then we will compute the silhouette."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "km = KMeans(n_clusters=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustering sparse data with KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=300,\n",
      "    n_clusters=2, n_init=10, n_jobs=None, precompute_distances='auto',\n",
      "    random_state=None, tol=0.0001, verbose=0)\n",
      "done in 0.934s\n"
     ]
    }
   ],
   "source": [
    "print(\"Clustering sparse data with %s\" % km)\n",
    "t0 = time()\n",
    "km.fit(tfidf)\n",
    "print(\"done in %0.3fs\" % (time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silhouette score for 2 clusters: 0.22292668296056226\n"
     ]
    }
   ],
   "source": [
    "s = metrics.silhouette_score(tfidf, km.labels_)\n",
    "print(\"Silhouette score for 2 clusters: %s\" % s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's try with 10 clusters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "km = KMeans(n_clusters=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustering sparse data with KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=300,\n",
      "    n_clusters=10, n_init=10, n_jobs=None, precompute_distances='auto',\n",
      "    random_state=None, tol=0.0001, verbose=0)\n",
      "done in 1.347s\n"
     ]
    }
   ],
   "source": [
    "print(\"Clustering sparse data with %s\" % km)\n",
    "t0 = time()\n",
    "km.fit(tfidf)\n",
    "print(\"done in %0.3fs\" % (time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silhouette score for 10 clusters: 0.5173402000768418\n"
     ]
    }
   ],
   "source": [
    "s = metrics.silhouette_score(tfidf, km.labels_)\n",
    "print(\"Silhouette score for 10 clusters: %s\" % s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now let's get the cluster number per text:\n",
    "cluster_kmeans = pd.Series(km.labels_,index=texts.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering using the cosine similarity\n",
    "This technique uses word vectors approach. The text is transformed into a representation by wordvectors. Then, in a vectorized approach, using numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = [nlp(i) for i in data_samples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "simma = np.ma.arange(len(docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparer = lambda x: docs[idx].similarity(docs[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "vfunc = np.vectorize(comparer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 4.668s\n"
     ]
    }
   ],
   "source": [
    "similar_topics = []\n",
    "thr = 0.89\n",
    "t0 = time()\n",
    "for idx,val in enumerate(simma):\n",
    "    if simma[idx] is not np.ma.masked:\n",
    "        res = vfunc(simma)\n",
    "        topic_sim = np.ma.masked_where(res <= thr,res)\n",
    "        similar_topics.append(simma[~topic_sim.mask].compressed())\n",
    "        simma[~topic_sim.mask] = np.ma.masked\n",
    "print(\"done in %0.3fs\" % (time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = np.zeros(len(docs))\n",
    "for idx,i in enumerate(similar_topics):\n",
    "    for elem in i:\n",
    "        mapping[elem] = idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_cosine =  pd.Series(mapping,index=texts.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters_per_documents = pd.DataFrame({'lda':cluster_lda,'nmf1':cluster_nmf,'nmf2':cluster_nmf2,'kmeans':cluster_kmeans,'cosine':cluster_cosine})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = {}\n",
    "for i in range(0,10):\n",
    "    topics[i] = (clusters_per_documents == i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['lda', 'nmf1', 'nmf2', 'kmeans', 'cosine'], dtype='object')"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusters_per_documents[clusters_per_documents == 0].count().index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lda</th>\n",
       "      <th>nmf1</th>\n",
       "      <th>nmf2</th>\n",
       "      <th>kmeans</th>\n",
       "      <th>cosine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>lda</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.943126</td>\n",
       "      <td>0.943126</td>\n",
       "      <td>0.232121</td>\n",
       "      <td>-0.153717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nmf1</th>\n",
       "      <td>0.943126</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.233899</td>\n",
       "      <td>-0.161572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nmf2</th>\n",
       "      <td>0.943126</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.233899</td>\n",
       "      <td>-0.161572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kmeans</th>\n",
       "      <td>0.232121</td>\n",
       "      <td>0.233899</td>\n",
       "      <td>0.233899</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.218054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cosine</th>\n",
       "      <td>-0.153717</td>\n",
       "      <td>-0.161572</td>\n",
       "      <td>-0.161572</td>\n",
       "      <td>-0.218054</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             lda      nmf1      nmf2    kmeans    cosine\n",
       "lda     1.000000  0.943126  0.943126  0.232121 -0.153717\n",
       "nmf1    0.943126  1.000000  1.000000  0.233899 -0.161572\n",
       "nmf2    0.943126  1.000000  1.000000  0.233899 -0.161572\n",
       "kmeans  0.232121  0.233899  0.233899  1.000000 -0.218054\n",
       "cosine -0.153717 -0.161572 -0.161572 -0.218054  1.000000"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusters_per_documents.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>cosine</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lda</th>\n",
       "      <th>kmeans</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"8\" valign=\"top\">0</th>\n",
       "      <th>0</th>\n",
       "      <td>646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"9\" valign=\"top\">1</th>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">2</th>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"8\" valign=\"top\">3</th>\n",
       "      <th>1</th>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"8\" valign=\"top\">4</th>\n",
       "      <th>0</th>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">6</th>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <th>4</th>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">8</th>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">9</th>\n",
       "      <th>2</th>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           cosine\n",
       "            count\n",
       "lda kmeans       \n",
       "0   0         646\n",
       "    2          11\n",
       "    4           2\n",
       "    5         116\n",
       "    6           3\n",
       "    7           2\n",
       "    8          18\n",
       "    9           9\n",
       "1   1          18\n",
       "    2           3\n",
       "    3           1\n",
       "    4           8\n",
       "    5          10\n",
       "    6           9\n",
       "    7         134\n",
       "    8          12\n",
       "    9          28\n",
       "2   1           1\n",
       "    8          97\n",
       "3   1         118\n",
       "    2           2\n",
       "    3           3\n",
       "    4           1\n",
       "    5           1\n",
       "    6          10\n",
       "    8           3\n",
       "    9          16\n",
       "4   0          51\n",
       "    2           4\n",
       "    4           3\n",
       "    5           1\n",
       "    6          11\n",
       "    7           5\n",
       "    8           4\n",
       "    9         124\n",
       "6   2           1\n",
       "    4           1\n",
       "    6         141\n",
       "7   4         105\n",
       "8   1           2\n",
       "    2         114\n",
       "    4           2\n",
       "    6           1\n",
       "9   2          16\n",
       "    3         119\n",
       "    5           1\n",
       "    6          10\n",
       "    8           2"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusters_per_documents[['cosine','lda','kmeans']].groupby(['lda','kmeans']).agg({'cosine':['count']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lda</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cosine</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>1562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19.0</th>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7.0</th>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29.0</th>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34.0</th>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16.0</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35.0</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.0</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22.0</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13.0</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15.0</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20.0</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52.0</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27.0</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31.0</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36.0</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57.0</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         lda\n",
       "cosine      \n",
       "0.0     1562\n",
       "2.0       59\n",
       "19.0      35\n",
       "3.0       31\n",
       "1.0       20\n",
       "7.0       18\n",
       "29.0      14\n",
       "34.0      12\n",
       "16.0      10\n",
       "35.0      10\n",
       "4.0        9\n",
       "22.0       7\n",
       "13.0       6\n",
       "15.0       5\n",
       "20.0       5\n",
       "52.0       5\n",
       "27.0       4\n",
       "31.0       4\n",
       "36.0       4\n",
       "57.0       4"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusters_per_documents[['lda','cosine']].groupby('cosine').count().nlargest(20,'lda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
